{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/al34n1x/DataScience/blob/master/6.Gestion_de_datos/Gestion_de_datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5ixhOWpDnNt",
        "colab_type": "toc"
      },
      "source": [
        ">[Gestión de datos: Join, Combine, y Reshape](#updateTitle=true&folderId=1hYY6URNFLa2w5I3uQbpDlwOox_am-5cM&scrollTo=37Vujga1JOOK)\n",
        "\n",
        ">>[Indice Jerárquico](#updateTitle=true&folderId=1hYY6URNFLa2w5I3uQbpDlwOox_am-5cM&scrollTo=g-QfwPOyJ0JO)\n",
        "\n",
        ">>[Reordenando los diferentes niveles](#updateTitle=true&folderId=1hYY6URNFLa2w5I3uQbpDlwOox_am-5cM&scrollTo=fW0-QPnwM2X2)\n",
        "\n",
        ">>[Indexing columnas en un Dataframe](#updateTitle=true&folderId=1hYY6URNFLa2w5I3uQbpDlwOox_am-5cM&scrollTo=5nEdvsjbPN9y)\n",
        "\n",
        ">[Combinando datasets](#updateTitle=true&folderId=1hYY6URNFLa2w5I3uQbpDlwOox_am-5cM&scrollTo=ONyrRGhIQQaE)\n",
        "\n",
        ">>[Database-Style joins en Dataframes](#updateTitle=true&folderId=1hYY6URNFLa2w5I3uQbpDlwOox_am-5cM&scrollTo=4aHveRwpQkdS)\n",
        "\n",
        ">>>[Argumentos de la función Merge](#updateTitle=true&folderId=1hYY6URNFLa2w5I3uQbpDlwOox_am-5cM&scrollTo=S3dWfNjVkOfp)\n",
        "\n",
        ">>[Merge en el índice](#updateTitle=true&folderId=1hYY6URNFLa2w5I3uQbpDlwOox_am-5cM&scrollTo=SnS0Dvcs0pFL)\n",
        "\n",
        ">>[Concatenando entre ejes](#updateTitle=true&folderId=1hYY6URNFLa2w5I3uQbpDlwOox_am-5cM&scrollTo=DI3tPxyq4z_l)\n",
        "\n",
        ">>[Reshaping y Pivot](#updateTitle=true&folderId=1hYY6URNFLa2w5I3uQbpDlwOox_am-5cM&scrollTo=VqNU7hfT7B75)\n",
        "\n",
        ">>>[Pivotar el formato \"largo\" a \"ancho\"](#updateTitle=true&folderId=1hYY6URNFLa2w5I3uQbpDlwOox_am-5cM&scrollTo=AKcrY6W3ADtt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37Vujga1JOOK"
      },
      "source": [
        "# Gestión de datos: Join, Combine, y Reshape\n",
        "\n",
        "En muchas aplicaciones, los datos están distribuidos en diferentes archivos o base de datos, o en un formato que no es fácil de analizar.\n",
        "\n",
        "Para ello, utilizaremos herramientas que nos facilitarán el proceso de preparación de los datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-QfwPOyJ0JO"
      },
      "source": [
        "## Indice Jerárquico\n",
        "\n",
        "Los índices jerárquicos nos permiten tener múltiples índices en un mismo eje.\n",
        "\n",
        "Esto nos permitiría visualizar datos de una dimensión superior en una inferior (Ejemplo: ventas indexadas primero por local y dentro de cada local, a través del tiempo)\n",
        "\n",
        "Esta es una herramienta de Pandas que ya vimos anteriormente, pero ahora vamos a dar ejemplos diferentes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E71q1egDJBEp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.Series(np.random.randn(9),\n",
        "                 index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n",
        "                        [1, 2, 3, 1, 3, 1, 2, 2, 3]])\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIKxDh-yLQf3"
      },
      "source": [
        "Lo que está viendo es una vista predefinida de una Serie con un MultiIndex como índice. Los espacios en la visualización del índice significan \"usar la etiqueta directamente arriba\".\n",
        "Con este tipo de índices puedes realizar lo que se llama partial-index, lo que permite obtener un subset de los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3acL0c9LmhI"
      },
      "source": [
        "data['b']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-HSqi0ULyES"
      },
      "source": [
        "data.loc[:, 2] # La selección es posible incluso desde dentro del nivel\n",
        "# En este caso se hace \"loc\" que es filtrado por nombre de indice, pero como\n",
        "# el indice tiene de nombre \"2\", se queda con esa clave."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W6k8FuPMOUs"
      },
      "source": [
        "Los índices jerárquicos juegan un rol importante en el modelado y agrupamiento de datos. Por ejemplo, podemos reordenar los datos anteriores en un Dataframe usando el método **unstack**.\n",
        "\n",
        "Desapilar podría introducir datos faltantes si no se encuentran todos los valores en el nivel en cada uno de los subgrupos:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "SN4WmGWHB9SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTs0n3XVMlKy"
      },
      "source": [
        "obj_desapilado = data.unstack()\n",
        "obj_desapilado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNPfvGC2MrO8"
      },
      "source": [
        "obj_apilado = obj_desapilado.stack() # Es la función inversa\n",
        "obj_apilado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW0-QPnwM2X2"
      },
      "source": [
        "## Reordenando los diferentes niveles\n",
        "Con los Dataframe, los ejes pueden tener índice jerárquicos también. Veamos el siguiente ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1YpZCTZM14I"
      },
      "source": [
        "df = pd.DataFrame(np.arange(12).reshape((4, 3)),\n",
        "                     index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\n",
        "                     columns=[['Marty', 'Marty', 'Doc'],\n",
        "                              ['Lorraine', 'George', 'Delorean']])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izL50eEaNyTX"
      },
      "source": [
        "df.index.names = ['key1', 'key2'] # Los niveles pueden tener nombres.\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9wShIDgN81e"
      },
      "source": [
        "df['Marty'] # Podemos seleccionar datos parciales"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mb1Xn6XOG2C"
      },
      "source": [
        "df.swaplevel('key1','key2') # También es posible reordenar por niveles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR3X9lmvOloE"
      },
      "source": [
        "Finalmente, podemos aplicar funciones estadísticas en Dataframes o series, como agregación en un eje particular.\n",
        "Considerando el ejemplo anterior, podemos realizar una agregación por nivel, ya sea por fila o columna:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oxBAT-5OkUX"
      },
      "source": [
        "df.sum(level='key2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nEdvsjbPN9y"
      },
      "source": [
        "## Indexing columnas en un Dataframe\n",
        "Es muy común que algunas veces desees mover algunos índices de columnas a filas, o viceversa. Para ello podemos utilizar la función **set_index**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZkcVpCgPNhh"
      },
      "source": [
        "df = pd.DataFrame({'a': range(7),\n",
        "                   'b': range(7, 0, -1),\n",
        "                   'c': ['one', 'one', 'one', 'two', 'two', 'two', 'two'],\n",
        "                   'd': [0, 1, 2, 0, 1, 2, 3]})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "143QWLFvPjPP"
      },
      "source": [
        "df2 = df.set_index(['c', 'd'])\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si agregamos el parámetro drop = False, las columnas c y d pasarán a ser índices de fila, pero también se mantendrán las columnas originales con sus valores correspondientes:"
      ],
      "metadata": {
        "id": "B12HCDYfRU2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df.set_index(['c', 'd'], drop = False)\n",
        "df3"
      ],
      "metadata": {
        "id": "SJUVNk8YRKGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONyrRGhIQQaE"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Combinando datasets\n",
        "\n",
        "Los datos contenidos en los objetos Pandas se pueden combinar de varias maneras:\n",
        "\n",
        "\n",
        "\n",
        "*   **pandas.merge** conecta filas en DataFrames en función de una o más claves. Esto será familiar para los usuarios de SQL u otras bases de datos relacionales, ya que implementa operaciones de unión de bases de datos.\n",
        "*   **pandas.concat** concatena o \"apila\" objetos juntos a lo largo de un eje.\n",
        "*   **combine_first** permite unir datos superpuestos para completar los valores faltantes en un objeto con valores de otro.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHveRwpQkdS"
      },
      "source": [
        "## Database-Style joins en Dataframes\n",
        "\n",
        "Las operaciones de **merge** o **join** combinan conjuntos de datos al vincular filas con una o más claves. Estas operaciones son centrales para las bases de datos relacionales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONe0mhEWQ6sE"
      },
      "source": [
        "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
        "                    'data1': range(7)})\n",
        "df2 = pd.DataFrame({'key': ['a', 'b', 'd'],\n",
        "                    'data2': range(3)})\n",
        "print(df1)\n",
        "print('\\n')\n",
        "print(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vxjkZqRTIHY"
      },
      "source": [
        "Este es un ejemplo de una unión de muchos a uno; los datos en df1 tienen varias filas etiquetadas con a y b, mientras que df2 tiene solo una fila para cada valor en la columna clave. Llamando a fusionar con estos objetos obtenemos:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk5aY6AnRLF2"
      },
      "source": [
        "pd.merge(df1,df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkeN9A15f4vO"
      },
      "source": [
        "Puedes observar que no especifiqué en qué columna unir. Si no se especifica esa información, la combinación usa los nombres de columna superpuestos (es decir, los nombres en comun que tengan ambos dataframes) como las claves. Sin embargo, es una buena práctica especificar explícitamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHzz4hdWgCP-"
      },
      "source": [
        "pd.merge(df1, df2, on='key')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW4ACge7gQA2"
      },
      "source": [
        "Como en las sentencias SQL, si los nombres de las columnas son diferentes en cada objeto, se puede especificar de forma separada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz5Z3qP2gaqz"
      },
      "source": [
        "df3 = pd.DataFrame({'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
        "                    'data1': range(7)})\n",
        "df4 = pd.DataFrame({'rkey': ['a', 'b', 'd'],\n",
        "                    'data2': range(3)})\n",
        "print (df3)\n",
        "print('\\n')\n",
        "print(df4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.merge(df3,df4)"
      ],
      "metadata": {
        "id": "Wy9vyUs_E1TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53qGPFYegjVI"
      },
      "source": [
        "pd.merge(df3, df4, left_on='lkey', right_on='rkey')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyFw4iWhh17Z"
      },
      "source": [
        "Puedes notar que los valores **c** y **d** y los datos asociados faltan en el resultado. Por defecto, merge hace una unión 'interna' (inner join); Las claves en el resultado son la intersección, o el conjunto común que se encuentra en ambas tablas. Otras opciones posibles son **izquierda**, **derecha** y **exterior**. La unión externa toma la unión de las claves, combinando el efecto de aplicar las uniones izquierda y derecha.\n",
        "A continuación encontrarás un diagrama con de SQL joins con su correspondiente sentencia en ese lenguaje que te será de utilidad para el desarrollo de tus actividades\n",
        "\n",
        "<img src = \"https://i.pinimg.com/564x/42/48/72/424872ac0b25c05e117b521d55616551.jpg\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHnXpV7JjDda"
      },
      "source": [
        "A continuación se detallan las opciones que se encuentran disponibles en Pandas con el compartamiento asociado\n",
        "\n",
        "Opción | Comportamiento\n",
        "-------|-------\n",
        "**inner**| Utiliza solo la combinación de claves comunes para ambas tablas\n",
        "**left** | Utiliza solo la combinación de claves encontradas en la tabla declarada a izquierda\n",
        "**right** | Utiliza solo la combinación de claves encontradas en la tabla declarada a derecha\n",
        "**outer** | Utiliza solo la combinación de claves observada en ambas tablas juntas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlLsqB4bVOTz"
      },
      "source": [
        "df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],\n",
        "                    'data1': range(7)})\n",
        "df2 = pd.DataFrame({'key': ['a', 'b', 'd'],\n",
        "                    'data2': range(3)})\n",
        "print(df1)\n",
        "print('\\n')\n",
        "print(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v86X2n76iuZH"
      },
      "source": [
        "pd.merge(df1, df2, how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKv8o0Xmj7M9"
      },
      "source": [
        "Para realizar merge con multiples keys, debemos pasar una lista de nombres de columnas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6I4PUfYjxuq"
      },
      "source": [
        "left = pd.DataFrame({'key1': ['foo', 'foo', 'bar'],\n",
        "                     'key2': ['one', 'two', 'one'],\n",
        "                     'lval': [1, 2, 3]})\n",
        "right = pd.DataFrame({'key1': ['foo', 'foo', 'bar', 'bar'],\n",
        "                      'key2': ['one', 'one', 'one', 'two'],\n",
        "                      'rval': [4, 5, 6, 7]})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLqjUY9DVjmb"
      },
      "source": [
        "print (left)\n",
        "print ('\\n')\n",
        "print(right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpTQIyBhVjAh"
      },
      "source": [
        "pd.merge(left, right, on=['key1', 'key2'], how='inner')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3dWfNjVkOfp"
      },
      "source": [
        "###Argumentos de la función **Merge**\n",
        "\n",
        "A continuación se detallan los argumentos más utilizados con la función **merge** asociados a su descripción.\n",
        "\n",
        "Argumento | Descripción\n",
        "---------|------------\n",
        "left | Dataframe se fusiona en el lado izquierdo\n",
        "right | Data frame se fusiona en el lado derecho\n",
        "how | con parámetro 'inner', 'outer', 'left', o 'right'. Default 'inner'\n",
        "on | La unión se hace en base a nombre de columnas. Deben estar presentes en ambos Dataframes\n",
        "left_on| Se utilizan las columnas del Dataframe izquierdo como claves\n",
        "right_on| Análogo al 'left_on'\n",
        "left_index|Utiliza  el índice de fila en la izquierda como clave del join.\n",
        "right_index|Análogo al 'left_index'\n",
        "sort | Ordena datos fusionados lexicográficamente por las claves.\n",
        "suffixes|Tupla de valores de cadenas a agregar a una coluna en caso de sobreposición. Si por ejemplo tenemos data en ambos dataframes podemos agregar data_x, data_y como sufijos\n",
        "copy|Si es falso, evita copiar datos en la estructura resultante.\n",
        "indicator|Agrega una columna especial '_merge' que indica la fuente de cada fila. Valores pueden ser 'left_only', 'right_only', o, 'both'.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnS0Dvcs0pFL"
      },
      "source": [
        "## Merge en el índice\n",
        "\n",
        "En algunos casos, la clave del merge se dará en el índice. En este caso, puedes pasar el parámetro **left_index=true** o **right_index=true** (o ambos) para indicar que el índice será usado como clave de merge.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcnLxyc8kN_X"
      },
      "source": [
        "left1 = pd.DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'],\n",
        "              'value': range(6)})\n",
        "\n",
        "right1 = pd.DataFrame({'group_val': [3.5, 7]}, index=['a', 'b'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYQ8V4Im1JbB"
      },
      "source": [
        "print (left1)\n",
        "print ('\\n')\n",
        "print (right1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8X1IO561X_c"
      },
      "source": [
        "pd.merge(left1, right1, left_on='key', right_index=True, how = 'inner') # Qué sucede aquí?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZYtarz81uK4"
      },
      "source": [
        "pd.merge(left1, right1, left_on='key', right_index=True, how='outer') # y aquí?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "474Qv0s23ywY"
      },
      "source": [
        "left2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]],\n",
        "            index=['a', 'c', 'e'],\n",
        "            columns=['Devoto', 'Palermo'])\n",
        "\n",
        "right2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]],\n",
        "            index=['b', 'c', 'd', 'e'],\n",
        "            columns=['Belgrano', 'Colegiales'])\n",
        "\n",
        "otro_df= pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [16., 17.]],\n",
        "            index=['a', 'c', 'e', 'f'],\n",
        "            columns=['Villa Urquiza', 'Nuñez'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9yxFSkIoBrY"
      },
      "source": [
        "left2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhQ5XfnBoDJ4"
      },
      "source": [
        "right2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNfec04OoETI"
      },
      "source": [
        "otro_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMJ_aL9I4Kwt"
      },
      "source": [
        "Para merge simples de índice sobre índice, puede pasar una lista de DataFrames para unirse como alternativa al uso de la función concat más general que se describe en la siguiente sección.\n",
        "\n",
        "En este caso, los índices del dataframe al que le aplico el join son los que se mantendrán:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XJA8gWW4KQB"
      },
      "source": [
        "left2.join([right2, otro_df])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI3tPxyq4z_l"
      },
      "source": [
        "## Concatenando entre ejes\n",
        "Otro tipo de operación de combinación de datos se conoce indistintamente como concatenación, enlace o apilamiento. La función concatenada de NumPy puede hacer esto con las matrices NumPy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzuuLCMt4-0B"
      },
      "source": [
        "arreglo = np.arange(12).reshape((3,4))\n",
        "arreglo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxKF1G-o5Jt1"
      },
      "source": [
        "np.concatenate([arreglo, arreglo], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BToz4P3q5WIn"
      },
      "source": [
        "En el contexto de objetos pandas como Series y DataFrame, tener ejes etiquetados le permite generalizar aún más la concatenación de matriz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXV6fRXC5X4w"
      },
      "source": [
        "s1 = pd.Series([0, 1], index=['a', 'b'])\n",
        "s2 = pd.Series([2, 3, 4], index=['c', 'd', 'e'])\n",
        "s3 = pd.Series([5, 6], index=['f', 'g'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsVLUmjx5cke"
      },
      "source": [
        "pd.concat([s1, s2, s3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMty7o8F5nsO"
      },
      "source": [
        "Por defecto, concat funciona a lo largo de axis = 0, produciendo otra serie. Si pasa axis = 1, el resultado será un DataFrame (axis = 1 son las columnas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb4gu7L35pt8"
      },
      "source": [
        "pd.concat([s1, s2, s3], axis=1) #Observar que tras correr este concat, las \"columnas\" hacen referencia al dataframe de origen de cada dato"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsD8IV7e6ggD"
      },
      "source": [
        "pd.concat([s1, s2, s3], axis=1, keys=['s1', 's2', 's3'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqNU7hfT7B75"
      },
      "source": [
        "## Reshaping y Pivot\n",
        "\n",
        "Existen varias operaciones básicas para reorganizar datos tabulares. Estos se denominan alternativamente operaciones de Reshaping y Pivot.\n",
        "\n",
        "La indexación jerárquica proporciona una forma consistente de reorganizar los datos en un DataFrame. Hay dos acciones principales:\n",
        "\n",
        "*   **Apilar**: Esto \"gira\" las columnas en los datos a las filas\n",
        "*   **Desapilar**: Esto gira de las filas a las columnas\n",
        "\n",
        "Ilustraremos estas operaciones a través de una serie de ejemplos. Considere un pequeño DataFrame con matrices de cadenas como índices de fila y columna:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fck2TAtH7nlJ"
      },
      "source": [
        "data = pd.DataFrame(np.arange(6).reshape((2, 3)),\n",
        "                    index=pd.Index(['Ohio', 'Colorado'], name='Estado'),\n",
        "                    columns=pd.Index(['Uno', 'Dos', 'Tres'], name='Número'))\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2vQbyZi72Zl"
      },
      "source": [
        "resultado = data.stack()\n",
        "resultado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08BNlOP1988_"
      },
      "source": [
        "Hasta ahora, este ejemplo es similar al que vimos al principio de la clase, ahora vayamos más allá.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlh6siUj-B1o"
      },
      "source": [
        "df = pd.DataFrame({'left': resultado,\n",
        "                   'right': resultado + 5},\n",
        "                  columns=pd.Index(['left', 'right'], name='Lado'))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**¿Qué sucede si apilamos/desapilamos sobre un índice?**\n",
        "\n",
        "Cuando se desapila en un DataFrame, el nivel desapilado se convierte en el nivel más bajo en el resultado:"
      ],
      "metadata": {
        "id": "eJY3u88tcYtw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-s6LYEM-Nfn"
      },
      "source": [
        "df.unstack('Estado')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-IKX8EZ-XVu"
      },
      "source": [
        "df.unstack('Estado').stack('Lado')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = df.unstack('Estado').stack('Lado')\n",
        "df_new"
      ],
      "metadata": {
        "id": "qDFQq9d5GNti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_colorado = df_new[['Colorado']]\n",
        "df_colorado"
      ],
      "metadata": {
        "id": "jjEOYdeTGrJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKcrY6W3ADtt"
      },
      "source": [
        "### Pivotar el formato \"largo\" a \"ancho\"\n",
        "\n",
        "Una forma común de almacenar múltiples series de tiempo en bases de datos y CSV es en el llamado formato largo o apilado. Carguemos algunos datos de ejemplo y hagamos una pequeña cantidad de disputas de series de tiempo y otra limpieza de datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JqYKj1qAED6"
      },
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/manquintana/Finlab-UADE/main/Ejercitacion/Datasets/macrodata.csv')\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KENkLwInAF8x"
      },
      "source": [
        "periodos = pd.PeriodIndex(year=data.year, quarter=data.quarter, name='fecha') #El método PeriodIndex combina las columnas de año y trimestre\n",
        "                                                                              # para crear un tipo de intervalo de tiempo.\n",
        "\n",
        "columnas = pd.Index(['realgdp', 'infl', 'unemp'], name='item')\n",
        "data = data.reindex(columns=columnas) # reindex le cambia el indice a un Dataframe\n",
        "\n",
        "data.index = periodos.to_timestamp(freq='D', how = 'end') # Castea los valores \"year-quarter\" que definimos arriba a tipo DateTimeIndex\n",
        "# freq = 'D' is \"default\"\n",
        "# Si el parametro how = \"start\" --> Para el year: 1959, quarter: 01 asignará el valor \"1959-01-01\"\n",
        "# Si el parametro how= \"end\" --> Asignará el valor \"1959-03-31\"\n",
        "\n",
        "ldata = data.stack().reset_index().rename(columns={0: 'valor'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9LMTt6aAMUs"
      },
      "source": [
        "ldata[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bueno, esto está medio raro. ¿En verdad la hora es un dato relevante?"
      ],
      "metadata": {
        "id": "4-TSW4HPfvP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "ldata['fecha'] = ldata['fecha'].dt.strftime('%Y-%m-%d')\n",
        "ldata.head(10)"
      ],
      "metadata": {
        "id": "0sV0QqCzf1QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmBp0LxpCicz"
      },
      "source": [
        "Este es el llamado formato largo para múltiples series de tiempo u otros datos de observación con dos o más claves (aquí, nuestras claves son fecha y elemento). Cada fila de la tabla representa una sola observación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPiGXQ4tCqkP"
      },
      "source": [
        "Los datos se almacenan con frecuencia de esta manera en bases de datos relacionales como MySQL, ya que un esquema fijo (nombres de columna y tipos de datos) permite que el número de valores distintos en la columna del elemento cambie a medida que se agregan datos a la tabla.\n",
        "\n",
        "En el ejemplo anterior, la fecha y el elemento generalmente serían las claves principales (en el lenguaje de la base de datos relacional), ofreciendo integridad relacional y uniones más fáciles. En algunos casos, los datos pueden ser más difíciles de trabajar en este formato; es posible que prefieras tener un DataFrame que contenga una columna por valor de elemento distinto indexado por marcas de tiempo en la columna de fecha. El método pivote de DataFrame realiza exactamente esta transformación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeFN_4ehAPAZ"
      },
      "source": [
        "pivoted = ldata.pivot('fecha', 'item', 'valor') # Los primeros dos valores son las columnas que se utilizarán\n",
        "# respectivamente como el índice de fila y columna, luego, finalmente, una columna de valor opcional para llenar el DataFrame.\n",
        "pivoted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfzLyzOlC5CM"
      },
      "source": [
        " Suponga que tiene dos columnas de valor que desea remodelar simultáneamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnp_8vHtASwl"
      },
      "source": [
        "ldata['valor2'] = np.random.randn(len(ldata))\n",
        "ldata[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhH-b6wKDReJ"
      },
      "source": [
        "Omitiendo el último argumento, obtienes un DataFrame con columnas jerárquicas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOeK14sEAVPy"
      },
      "source": [
        "pivoted = ldata.pivot('fecha', 'item')\n",
        "pivoted[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ9w3UAqB-FG"
      },
      "source": [
        "pivoted['valor'][:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnGABHVCDe4r"
      },
      "source": [
        "Pivot es equivalente a crear un índice jerárquico usando **set_index** seguido de una llamada para desapilar. Claramente, es preferible utilizar pivot en su lugar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo0rSzKuAXYB"
      },
      "source": [
        "unstacked = ldata.set_index(['fecha', 'item']).unstack('item')\n",
        "unstacked[:7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZwm56LqDw_6"
      },
      "source": [
        "### Pivotar el formato \"ancho\" a \"largo\"\n",
        "\n",
        "Una operación inversa para pivotar en DataFrames es **pandas.melt**. En lugar de transformar una columna en muchas en un nuevo DataFrame, combina varias columnas en una, produciendo un DataFrame que es más largo que la entrada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os6a2-ekEFHF"
      },
      "source": [
        "df = pd.DataFrame({'key': ['foo', 'bar', 'baz'],\n",
        "                   'A': [1, 2, 3],\n",
        "                   'B': [4, 5, 6],\n",
        "                   'C': [7, 8, 9]})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXpKf5I9ELGo"
      },
      "source": [
        "union = pd.melt(df, ['key'])\n",
        "union"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHvxvMNuETb1"
      },
      "source": [
        "'''\n",
        "Usando pivot, podemos volver a dar forma al diseño original\n",
        "'''\n",
        "reshaped = union.pivot('key', 'variable', 'value')\n",
        "reshaped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vICfQXAExXs"
      },
      "source": [
        "Dado que el resultado de pivot crea un índice a partir de la columna utilizada como etiquetas de fila, es posible que queramos usar reset_index para mover los datos nuevamente a una columna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nlpp2yEkEfXl"
      },
      "source": [
        "reshaped.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYQE3OWwEn2j"
      },
      "source": [
        "pd.melt(df, id_vars=['key'], value_vars=['A', 'B'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}